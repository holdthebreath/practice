# 分布式

### 分布式锁

在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行。

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508094706.image)

**redis分布式锁**：

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508094758.image)

**Redis实现分布式锁需要自己编写代码实现，而Zookeeper通过自身的顺序临时节点来实现分布式锁和等待队列。**

Redis实现分布式锁的三大致命问题：

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508094850.image)

### zookeeper

**zookeeper=文件系统的数据模型结构+监听通知机制（Watch）**

Zookeeper的数据模型结构很像数据结构当中的树，也很像文件系统中的目录。树是由所有节点组成,Zookeeper的数据存储也同样是基于节点，这种节点叫做**Znode**。但是，不同于树的节点，Znode的引用方式是路径引用，类似于文件系统，通过路径进行访问数据，每个znode有唯一路径。

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508095207.image)

**Znode 包含哪些元素**

- data: Znode存储的数据信息
- ACL：记录Znode的访问权限，那些人或者哪些IP可以访问本节点
- start: 包含Znode的各种元数据，比如事务ID、版本号、时间戳、大小等
- child: 当前节点的子节点

**Zookeeper适用于读多写少的场景，Znode并不是用来存储大规模数据，而是用于存储少量的状态和配置信息，每个节点的数据量不能超过1Mb**

#### zookeeper事件通知

`Watch`理解成是注册在特定Znode的触发器，当这个Znode发生改变，也就是调用了`create、delete、setData`写操作方法时，将会触发Znode上注册的对应事件，请求Watch的客户端会接收到异步通知。

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508095326.image)

**Zookeeper事件通知机制实现服务与注册功能，实现了分布式系统的高可用问题**。

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508095355.image)

#### zookeeper高可用

**Zookeeper集群的ZAB协议解决了两个问题：**

- 1、Zookeeper集群崩溃恢复
- 2、Zookeeper集群实现数据一致性、主从同步数据

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508095515.image)

##### Zookeeper集群采用ZAB协议解决崩溃恢复

1. 选举阶段：**当主节点的zookeeper服务挂了，再所有从节点中选举出准主节点**：

   ![img](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4d9d04a6e66449d786dfab2e0b335131~tplv-k3u1fbpfcp-zoom-1.image)

2. 发现阶段：**由于网络等原因选举出两个准主节点，就会出现写写冲突，如何处理？**：

    -  所有的从节点向两个准主节点发送epoch值，准主节点从中选出最大的epoch值，基于此值+1，生成新的epoch分发给各个从节点。

    - 各个从节点接收到epoch值后，返回ACK给准主节点，带上各自最大的ZXID值和历史事务日志，准主节点从中选出最大的ZXID值，并更新自身历史日志

3. 同步阶段：确定主节点：把准主节点刚才得到的最新历史事务日志，同步给集群中所有的从几点，只要半数以上的从节点同步成功，这个准主节点才能成为主节点

#### Zookeeper集群实现数据一致性、主从同步数据

**ZAB的数据写入：Broadcast广播阶段、就是Zookeeper常规情况下要更新数据的时候，由Leader主节点广播到所有的Follower从节点**

1. 客户端发出写入数据请求给任意Follower从节点
2. Follower把写入数据请求转发给Leader主节点（读写分离）
3. Leader主节点采用二阶段提交方式，先发送Propose广播给所有的Follower从节点（准备写数据，开启事务，开启一阶段提交）
4. Follower从节点接收到Propose消息，写入日志成功后（执行将数据写入日志中，但是没有提交），返回ACK消息给Loader主节点（说明准备就绪）
5. leader主节点接收到半数以上的ACK消息后，返回成功给客户端，并且广播提交请求给所有从节点，最后所有节点统一提交数据，完成数据的一致性

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508100717.image)

#### zookeeper应用场景

**1、分布式锁**：利用Zookeeper的临时顺序节点，可以轻松实现分布式锁

**2、分布式服务的注册和发现**：利用Znode和Watcher可以实现分布式服务的注册和发现，应用在阿里的分布式RPC框架Dubbo（**Kafka、Hbase、Hadoop也是依靠同步节点信息，实现高可用**）。

**一致性：强一致性、弱一致性、顺序一致性（Zookeeper默认采用）**

#### zookeeper分布式锁

**znode类型**：

1. 持久节点：默认的节点类型，创建节点的客户端断开连接后，该节点依旧存在
2. 持久顺序节点：顺序节点：在创建节点时，Zookeeper根据创建时间顺序会给该节点名称进行编号
3. 临时节点：当创建节点的客户端与Zookeeper断开连接之后，临时节点会删除
4. 临时顺序节点： 在创建节点时，Zookeeper根据创建时间顺序会给该节点名称进行编号，当创建节点的客户端与Zookeeper断开连接之后，临时节点会删除

zk分布式锁原理：zookeeper根据znode节点的临时顺序节点特性，客户端请求就创建临时有序节点（加锁），不再请求就删除（释放锁），当其他请求进来后，先查看是否有锁资源，如果有则依次创建有序的锁资源形成有序的锁队列。第二个请求会根据**watch**观察机制观察前一个锁资源的状态，当前一个请求释放锁后，遍历所有锁资源，发现有序锁队列中没有比自己锁序号小的，就相当于加锁操作，下一个请求会观察第二个请求锁资源的状态，以此类推。

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508100925.image)



### 分布式事务

分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。分布式事务就保证操作要么全部成功，要么全部失败。本质上来说，**分布式事务就是为了保证不同数据库的数据一致性**。

#### 强一致性、弱一致性、最终一致性

- 强一致性：任何一次读都能读到某个数据的最近一次写的数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。（在任意时刻，所有节点中的数据是一样的。）
- 弱一致性：数据更新后，如果能容忍后续的访问只能访问到部分或者全部访问不到，则是弱一致性。
- 最终一致性：不保证在任意时刻任意节点上的同一份数据都是相同的，但是随着时间的迁移，不同节点上的同一份数据总是在向趋同的方向变化。简单说，就是在一段时间后，节点间的数据会最终达到一致状态。

#### CAP 原则

CAP 原则又称 CAP 定理，指的是在一个分布式系统中， Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可得兼。

CAP 原则的精髓就是要么 AP，要么 CP，要么 AC，但是不存在 CAP。如果在某个分布式系统中数据无副本， 那么系统必然满足强一致性条件， 因为只有独一数据，不会出现数据不一致的情况，此时 C 和 P 两要素具备，但是如果系统发生了网络分区状况或者宕机，必然导致某些数据不可以访问，此时可用性条件就不能被满足，即在此情况下获得了 CP 系统，但是 CAP 不可同时满足。

#### BASE理论

BASE 理论指的是基本可用 Basically Available，软状态 Soft State，最终一致性 Eventual Consistency，核心思想是即便无法做到强一致性，但应该采用适合的方式保证最终一致性。

**柔性事务**：不同于 ACID 的刚性事务，在分布式场景下基于 BASE 理论，就出现了柔性事务的概念。

#### 分布式事务解决方案

##### 两阶段提交/XA

分两步提交。存在一个负责协调各个本地资源管理器的事务管理器，本地资源管理器一般是由数据库实现，事务管理器在第一阶段的时候询问各个资源管理器是否都就绪？如果收到每个资源的回复都是 yes，则在第二阶段提交事务，如果其中任意一个资源的回复是 no, 则回滚事务。

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508134655.jpg)

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508134706.jpg)

大致流程：

1. 第一阶段（prepare）：事务管理器向所有本地资源管理器发起请求，询问是否是 ready 状态，所有参与者都将本事务能否成功的信息反馈发给协调者；
2. 第二阶段 (commit/rollback)：事务管理器根据所有本地资源管理器的反馈，通知所有本地资源管理器，步调一致地在所有分支上提交或者回滚。

存在的问题：

1. 同步阻塞：当参与事务者存在占用公共资源的情况，其中一个占用了资源，其他事务参与者就只能阻塞等待资源释放，处于阻塞状态。
2. 单点故障：一旦事务管理器出现故障，整个系统不可用
3. 数据不一致：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。
4. 不确定性：当协事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。

##### TCC（Try-Confirm-Cancel）

1. Try 阶段：尝试执行，完成所有业务检查（一致性）, 预留必须业务资源（准隔离性）

2. Confirm 阶段：确认执行真正执行业务，不作任何业务检查，只使用 Try 阶段预留的业务资源，Confirm 操作满足幂等性。要求具备幂等设计，Confirm 失败后需要进行重试。
3. Cancel 阶段：取消执行，释放 Try 阶段预留的业务资源 Cancel 操作满足幂等性 Cancel 阶段的异常和 Confirm 阶段异常处理方案基本上一致。

在 Try 阶段，是对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。
基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高。

##### 本地消息表

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508135310.jpg)

1. 当系统 A 被其他系统调用发生数据库表更操作，首先会更新数据库的业务表，其次会往相同数据库的消息表中插入一条数据，两个操作发生在同一个事务中
2. 系统 A 的脚本定期轮询本地消息往 mq 中写入一条消息，如果消息发送失败会进行重试
3. 系统 B 消费 mq 中的消息，并处理业务逻辑。如果本地事务处理失败，会在继续消费 mq 中的消息进行重试，如果业务上的失败，可以通知系统 A 进行回滚操作

本地消息表实现的条件：

1. 消费者与生成者的接口都要支持幂等
2. 生产者需要额外的创建消息表
3. 需要提供补偿逻辑，如果消费者业务失败，需要生产者支持回滚操作

容错机制：

1. 步骤 1 失败时，事务直接回滚
2. 步骤 2、3 写 mq 与消费 mq 失败会进行重试
3. 步骤 3 业务失败系统 B 向系统 A 发起事务回滚操作

此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。

##### 可靠消息最终一致

![img](https://raw.githubusercontent.com/holdthebreath/picture-bed/master/20210508135606.jpg)

1. A 系统先向 mq 发送一条 prepare 消息，如果 prepare 消息发送失败，则直接取消操作
2. 如果消息发送成功，则执行本地事务
3. 如果本地事务执行成功，则想 mq 发送一条 confirm 消息，如果发送失败，则发送回滚消息
4. B 系统定期消费 mq 中的 confirm 消息，执行本地事务，并发送 ack 消息。如果 B 系统中的本地事务失败，会一直不断重试，如果是业务失败，会向 A 系统发起回滚请求
5. mq 会定期轮询所有 prepared 消息调用系统 A 提供的接口查询消息的处理情况，如果该 prepare 消息本地事务处理成功，则重新发送 confirm 消息，否则直接回滚该消息

### 尽最大努力通知

最大努力通知是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果 不影响主动方的处理结果。大致思路：

1. 系统 A 本地事务执行完之后，发送个消息到 MQ；
2. 这里会有个专门消费 MQ 的服务，这个服务会消费 MQ 并调用系统 B 的接口；
3. 要是系统 B 执行成功就 ok 了；要是系统 B 执行失败了，那么最大努力通知服务就定时尝试重新调用系统 B, 反复 N 次，最后还是不行就放弃。